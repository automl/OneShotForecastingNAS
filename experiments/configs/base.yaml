seed: 3

benchmark:
  dataset_root: ??? # Update this to the path to your own repository
  type: ???
  name: ???
  search_dataset_name: ???
  file_name: ???
  series_type: ???
  freq: ???
  external_forecast_horizon: ???
  do_normalization: ???


model:
  type: ???
  grad_order: ???
  model_type: ???

  seq_model:
    d_model: ???
    n_cells: ???
    n_nodes: ???
    n_cell_input_nodes: ???

    PRIMITIVES_encoder: [ 'mlp_mix','gru', 'lstm','transformer', 'tcn', 'sep_tcn','skip_connection' ]
    PRIMITIVES_decoder: [ 'mlp_mix','gru', 'lstm','transformer', 'tcn', 'sep_tcn','skip_connection' ]

  HEADs: ['quantile', 'mse', 'mae']

val_share: 0.5

model_dir: ${hydra:runtime.cwd}/ModelWeights # Update this to the path to store your model

train:
  n_epochs: 40
  n_epochs_eval: 100
  grad_clip: 0.1
  amp_enable: true
  targe_scaler: 'standard'

w_optimizer:
  type: 'sgd'
  lr: 0.025
  weight_decay: 0.0
  momentum: 0.9
  nesterov: true


a_optimizer_type: 'adam'
a_optimizer:
  type: 'adam'
  lr: 1e-3
  weight_decay: 1e-3
  beta1: 0.5
  beta2: 0.999

lr_scheduler:
  type: 'CosineAnnealingWarmRestarts'
  T_0: 20
  T_mult: 1
  eta_min: 1e-8

start_optimize_alpha: 0

w_optimizer_eval:
  type: 'adam'
  lr: 1e-3
  weight_decay: 0
  beta1: 0.9
  beta2: 0.999

lr_scheduler_eval:
  type: 'CosineAnnealingWarmRestarts'
  T_0: 20
  T_mult: 1
  eta_min: 1e-8


wandb:
  name: ${model.type}_${model.model_type}_${model.grad_order}
  group: ${benchmark.name}
  project: OneShotForecasting
  entity: abc
  mode: disabled
